{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Model Evaluation"],"metadata":{"id":"Jn3iBKqzZS6M"}},{"cell_type":"code","source":["print(\"üì¶ Installing required packages...\")\n","!pip -q install shap transformers peft torch scikit-learn matplotlib seaborn\n","\n","from __future__ import annotations\n","import os\n","import json\n","import math\n","import warnings\n","import pickle\n","from pathlib import Path\n","from typing import Dict, List, Optional\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from peft import LoraConfig, get_peft_model, TaskType\n","from tqdm import tqdm\n","\n","import matplotlib\n","matplotlib.use(\"agg\")  # Non-interactive backend for safe file saving\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.inspection import permutation_importance\n","\n","# Other utilities\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Optional SHAP\n","try:\n","    import shap  # noqa: F401\n","    _HAS_SHAP = True\n","except Exception:\n","    _HAS_SHAP = False\n","\n","# Set style for plots\n","plt.style.use('default')\n","sns.set_palette(\"husl\")\n","\n","print(\"‚úÖ All packages imported successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QquoqEDGZrdy","executionInfo":{"status":"ok","timestamp":1756600090721,"user_tz":-480,"elapsed":8591,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"9c7f906c-4ff0-43bf-9b6a-921b18926d3b"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing required packages...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ All packages imported successfully!\n"]}]},{"cell_type":"code","source":["# ============================\n","# Configuration\n","# ============================\n","print(\"‚öôÔ∏è Setting up configuration...\")\n","\n","CONFIG = {\n","    'base_path': '/content/drive/MyDrive/Tiktok_Hackaton',  # Adjust this path\n","    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n","    'batch_size': 32,\n","    'max_length': 512,\n","    'random_state': 42\n","}\n","\n","# Set random seeds for reproducibility\n","np.random.seed(CONFIG['random_state'])\n","torch.manual_seed(CONFIG['random_state'])\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(CONFIG['random_state'])\n","\n","print(f\"‚úÖ Configuration set. Using device: {CONFIG['device']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qs8cQGrfd6QV","executionInfo":{"status":"ok","timestamp":1756600090735,"user_tz":-480,"elapsed":4,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"e7363265-93d6-4837-89e4-eccf5caad05a"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["‚öôÔ∏è Setting up configuration...\n","‚úÖ Configuration set. Using device: cuda\n"]}]},{"cell_type":"code","source":["# ============================\n","# Model Classes (from training code)\n","# ============================\n","print(\"üèóÔ∏è Setting up model classes...\")\n","\n","class HybridClassificationModel(nn.Module):\n","    def __init__(self, num_labels, categorical_feature_dim, continuous_feature_dim,\n","                 categorical_vocab_sizes=None, dropout_rate=0.1, class_weights=None):\n","        super(HybridClassificationModel, self).__init__()\n","\n","        # Store class weights as buffer (handles device movement automatically)\n","        if class_weights is not None:\n","            self.register_buffer('class_weights', class_weights)\n","        else:\n","            self.register_buffer('class_weights', None)\n","\n","        # Text branch (DistilBERT with LoRA)\n","        self.distilbert = AutoModel.from_pretrained('distilbert-base-uncased')\n","\n","        lora_config = LoraConfig(\n","            r=8,\n","            lora_alpha=16,\n","            target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],\n","            lora_dropout=0.05,\n","            bias=\"none\",\n","            task_type=TaskType.FEATURE_EXTRACTION\n","        )\n","        self.distilbert = get_peft_model(self.distilbert, lora_config)\n","\n","        distilbert_hidden_size = self.distilbert.config.hidden_size\n","\n","        # Dynamic categorical embeddings\n","        if categorical_vocab_sizes is None:\n","            categorical_vocab_sizes = [5, 7, 24, 10]\n","\n","        self.categorical_embeddings = nn.ModuleList([\n","            nn.Embedding(vocab_size, min(50, vocab_size // 2 + 10))\n","            for vocab_size in categorical_vocab_sizes\n","        ])\n","\n","        total_cat_embed_dim = sum(emb.embedding_dim for emb in self.categorical_embeddings)\n","\n","        self.categorical_ffn = nn.Sequential(\n","            nn.Linear(total_cat_embed_dim, distilbert_hidden_size),\n","            nn.BatchNorm1d(distilbert_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate)\n","        )\n","\n","        self.continuous_ffn = nn.Sequential(\n","            nn.Linear(continuous_feature_dim, distilbert_hidden_size // 2),\n","            nn.BatchNorm1d(distilbert_hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(distilbert_hidden_size // 2, distilbert_hidden_size),\n","            nn.BatchNorm1d(distilbert_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate)\n","        )\n","\n","        combined_size = distilbert_hidden_size * 3\n","        self.classifier = nn.Sequential(\n","            nn.Linear(combined_size, distilbert_hidden_size),\n","            nn.BatchNorm1d(distilbert_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(distilbert_hidden_size, distilbert_hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(distilbert_hidden_size // 2, num_labels)\n","        )\n","\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for module in self.modules():\n","            if isinstance(module, nn.Linear):\n","                nn.init.xavier_uniform_(module.weight)\n","                if module.bias is not None:\n","                    nn.init.zeros_(module.bias)\n","            elif isinstance(module, nn.Embedding):\n","                nn.init.xavier_uniform_(module.weight)\n","\n","    def forward(self, input_ids, attention_mask, categorical_features, continuous_features, labels=None):\n","        # Text branch\n","        text_outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n","        text_hidden = text_outputs.last_hidden_state[:, 0, :]\n","\n","        # Categorical branch\n","        cat_embeddings = []\n","        for i, embedding_layer in enumerate(self.categorical_embeddings):\n","            feature_embedded = embedding_layer(categorical_features[:, i])\n","            cat_embeddings.append(feature_embedded)\n","\n","        cat_combined = torch.cat(cat_embeddings, dim=-1)\n","        cat_processed = self.categorical_ffn(cat_combined)\n","\n","        # Continuous branch\n","        cont_processed = self.continuous_ffn(continuous_features)\n","\n","        # Combine all branches\n","        combined_features = torch.cat((text_hidden, cat_processed, cont_processed), dim=-1)\n","        logits = self.classifier(combined_features)\n","\n","        loss = None\n","        if labels is not None:\n","            loss_fct = nn.CrossEntropyLoss(\n","                weight=self.class_weights,\n","                label_smoothing=0.1\n","            )\n","            loss = loss_fct(logits, labels)\n","\n","        return {\"loss\": loss, \"logits\": logits}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8UpsWZAZwpe","executionInfo":{"status":"ok","timestamp":1756600090757,"user_tz":-480,"elapsed":21,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"a8db102f-1027-4759-a873-00916c376db0"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["üèóÔ∏è Setting up model classes...\n"]}]},{"cell_type":"code","source":["# ============================\n","# Model Wrapper\n","# ============================\n","\n","class HybridModelWrapper:\n","    \"\"\"Wrapper to load and use the trained HybridClassificationModel for evaluation\"\"\"\n","\n","    def __init__(self, model_path, device=None):\n","        self.model_path = model_path\n","\n","        if device is None:\n","            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        else:\n","            self.device = device\n","\n","        # Load model artifacts\n","        self._load_model_artifacts()\n","\n","        # Initialize and load the model\n","        self._initialize_model()\n","\n","        print(f\"‚úÖ Hybrid model loaded successfully on device: {self.device}\")\n","\n","    def _load_model_artifacts(self):\n","        \"\"\"Load all model artifacts\"\"\"\n","        # Load hybrid model data\n","        hybrid_data_path = os.path.join(self.model_path, 'hybrid_model.bin')\n","        if not os.path.exists(hybrid_data_path):\n","            raise FileNotFoundError(f\"Model file not found: {hybrid_data_path}\")\n","\n","        self.hybrid_data = torch.load(hybrid_data_path, map_location='cpu')\n","\n","        # Load training metadata\n","        metadata_path = os.path.join(self.model_path, 'training_metadata.json')\n","        if os.path.exists(metadata_path):\n","            with open(metadata_path, 'r') as f:\n","                self.training_metadata = json.load(f)\n","        else:\n","            self.training_metadata = {}\n","\n","        # Extract configuration and metadata\n","        self.config = self.hybrid_data['config']\n","        self.feature_metadata = self.hybrid_data['feature_metadata']\n","        self.categorical_vocab_sizes = self.hybrid_data['categorical_vocab_sizes']\n","\n","        # Load class weights if available\n","        self.class_weights = None\n","        if 'class_weights' in self.hybrid_data and self.hybrid_data['class_weights'] is not None:\n","            self.class_weights = torch.tensor(self.hybrid_data['class_weights'], dtype=torch.float32)\n","\n","        # Load tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n","        if self.tokenizer.pad_token is None:\n","            self.tokenizer.pad_token = self.tokenizer.eos_token\n","\n","    def _initialize_model(self):\n","        \"\"\"Initialize and load the hybrid model\"\"\"\n","        # Get dimensions from metadata\n","        categorical_dim = self.feature_metadata['categorical_features']['feature_dim']\n","        continuous_dim = self.feature_metadata['continuous_features']['feature_dim']\n","\n","        # Create model instance\n","        self.model = HybridClassificationModel(\n","            num_labels=self.config['num_labels'],\n","            categorical_feature_dim=categorical_dim,\n","            continuous_feature_dim=continuous_dim,\n","            categorical_vocab_sizes=self.categorical_vocab_sizes,\n","            dropout_rate=self.config.get('regularization', {}).get('dropout_rate', 0.1),\n","            class_weights=self.class_weights\n","        )\n","\n","        # Load model weights\n","        model_state_dict = self.hybrid_data['full_model_state_dict'].copy()\n","\n","        # Remove class_weights from state dict if it exists\n","        if 'class_weights' in model_state_dict:\n","            del model_state_dict['class_weights']\n","\n","        # Load state dict\n","        self.model.load_state_dict(model_state_dict, strict=False)\n","\n","        # Move to device and set to eval mode\n","        self.model.to(self.device)\n","        self.model.eval()\n","\n","    def prepare_features(self, texts, all_features_df):\n","        \"\"\"Extract and prepare features for the given texts\"\"\"\n","        if isinstance(texts, str):\n","            texts = [texts]\n","\n","        # Get feature names\n","        cat_feature_names = self.feature_metadata['categorical_features']['feature_names']\n","        cont_feature_names = self.feature_metadata['continuous_features']['feature_names']\n","\n","        # Find matching features for each text\n","        categorical_data = []\n","        continuous_data = []\n","\n","        for text in texts:\n","            # Find matching row in features DataFrame\n","            matching_rows = all_features_df[all_features_df['review_text'] == text]\n","\n","            if not matching_rows.empty:\n","                row = matching_rows.iloc[0]\n","\n","                # Extract categorical features\n","                cat_features = []\n","                for i, col in enumerate(cat_feature_names):\n","                    if col in row:\n","                        val = int(row[col])\n","                        vocab_size = self.categorical_vocab_sizes[i]\n","                        val = max(0, min(val, vocab_size - 1))  # Clip to valid range\n","                        cat_features.append(val)\n","                    else:\n","                        cat_features.append(0)\n","\n","                # Extract continuous features\n","                cont_features = []\n","                for col in cont_feature_names:\n","                    if col in row:\n","                        val = float(row[col]) if not pd.isna(row[col]) else 0.0\n","                        cont_features.append(val)\n","                    else:\n","                        cont_features.append(0.0)\n","\n","            else:\n","                # No matching row found - use default values\n","                cat_features = [0] * len(cat_feature_names)\n","                cont_features = [0.0] * len(cont_feature_names)\n","\n","            categorical_data.append(cat_features)\n","            continuous_data.append(cont_features)\n","\n","        # Convert to tensors\n","        categorical_tensor = torch.tensor(categorical_data, dtype=torch.long).to(self.device)\n","        continuous_tensor = torch.tensor(continuous_data, dtype=torch.float32).to(self.device)\n","\n","        return categorical_tensor, continuous_tensor\n","\n","    def predict(self, texts, all_features_df, batch_size=32):\n","        \"\"\"Make predictions on texts and return both predictions and probabilities\"\"\"\n","        if isinstance(texts, str):\n","            texts = [texts]\n","\n","        all_predictions = []\n","        all_probabilities = []\n","\n","        # Process in batches\n","        for i in tqdm(range(0, len(texts), batch_size), desc=\"Making predictions\"):\n","            batch_texts = texts[i:i + batch_size]\n","\n","            # Tokenize texts\n","            encoded = self.tokenizer(\n","                batch_texts,\n","                padding=True,\n","                truncation=True,\n","                max_length=self.config.get('max_length', 512),\n","                return_tensors='pt'\n","            ).to(self.device)\n","\n","            # Prepare features\n","            categorical_features, continuous_features = self.prepare_features(batch_texts, all_features_df)\n","\n","            # Forward pass\n","            with torch.no_grad():\n","                outputs = self.model(\n","                    input_ids=encoded['input_ids'],\n","                    attention_mask=encoded['attention_mask'],\n","                    categorical_features=categorical_features,\n","                    continuous_features=continuous_features\n","                )\n","\n","            # Get predictions and probabilities\n","            logits = outputs['logits']\n","            probabilities = torch.softmax(logits, dim=-1)\n","            predictions = torch.argmax(probabilities, dim=-1)\n","\n","            all_predictions.extend(predictions.cpu().numpy())\n","            all_probabilities.extend(probabilities.cpu().numpy())\n","\n","        return np.array(all_predictions), np.array(all_probabilities)\n","\n","    def get_label_names(self):\n","        \"\"\"Get human-readable label names\"\"\"\n","        label_mapping = self.feature_metadata.get('label_mapping', {})\n","        if label_mapping:\n","            # Reverse mapping (value -> key)\n","            return [k for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n","        else:\n","            return [f\"Class_{i}\" for i in range(self.config['num_labels'])]"],"metadata":{"id":"8hvlo6T_Z8jf","executionInfo":{"status":"ok","timestamp":1756600090777,"user_tz":-480,"elapsed":5,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# ============================\n","# Evaluation Utilities\n","# ============================\n","\n","def _ensure_dir(path: str):\n","    os.makedirs(path, exist_ok=True)\n","\n","def _safe_proba_to_confidence(y_proba: Optional[np.ndarray], y_pred: np.ndarray) -> np.ndarray:\n","    \"\"\"Return confidence for predicted class or NaN if not available.\"\"\"\n","    if y_proba is None:\n","        return np.full(shape=(len(y_pred),), fill_value=np.nan, dtype=float)\n","    if y_proba.ndim == 1:  # binary shortcut (prob of class 1)\n","        return np.where(y_pred == 1, y_proba, 1.0 - y_proba)\n","    idx = np.arange(y_proba.shape[0])\n","    return y_proba[idx, y_pred]\n","\n","def _one_vs_rest_confusion(y_true: np.ndarray, y_pred: np.ndarray, positive_label: int) -> np.ndarray:\n","    \"\"\"2x2 confusion: [[TN, FP], [FN, TP]] for a one-vs-rest view.\"\"\"\n","    y_true_bin = (y_true == positive_label).astype(int)\n","    y_pred_bin = (y_pred == positive_label).astype(int)\n","    return confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n","\n","def per_class_metrics(y_true: np.ndarray, y_pred: np.ndarray, labels: List[str]) -> Dict:\n","    \"\"\"Return sklearn classification_report as a dict.\"\"\"\n","    rep = classification_report(\n","        y_true,\n","        y_pred,\n","        target_names=labels,\n","        output_dict=True,\n","        zero_division=0\n","    )\n","    return rep\n","\n","def plot_confusion_matrix_per_policy(\n","    y_true: np.ndarray,\n","    y_pred: np.ndarray,\n","    labels: List[str],\n","    out_dir: str\n",") -> Dict[str, str]:\n","    \"\"\"Save overall confusion matrix + one-vs-rest matrices. Return dict of file paths.\"\"\"\n","    _ensure_dir(out_dir)\n","    paths = {}\n","\n","    # Overall multiclass CM\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n","    fig, ax = plt.subplots(figsize=(8, 6))\n","    im = ax.imshow(cm, interpolation=\"nearest\", cmap='Blues')\n","    ax.set_title(\"Confusion Matrix - Overall\", fontsize=14, fontweight='bold')\n","    ax.set_xlabel(\"Predicted\", fontsize=12)\n","    ax.set_ylabel(\"True\", fontsize=12)\n","    ax.set_xticks(range(len(labels)))\n","    ax.set_yticks(range(len(labels)))\n","    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n","    ax.set_yticklabels(labels)\n","\n","    # Add text annotations\n","    for (i, j), v in np.ndenumerate(cm):\n","        ax.text(j, i, str(v), ha=\"center\", va=\"center\", fontsize=10,\n","                color=\"white\" if v > cm.max()/2 else \"black\")\n","\n","    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","    overall_pth = os.path.join(out_dir, \"confusion_overall.png\")\n","    plt.tight_layout()\n","    plt.savefig(overall_pth, dpi=300, bbox_inches='tight')\n","    plt.close(fig)\n","    paths[\"overall\"] = overall_pth\n","\n","    # One-vs-rest per class\n","    for idx, lbl in enumerate(labels):\n","        cm_bin = _one_vs_rest_confusion(y_true, y_pred, positive_label=idx)\n","        fig, ax = plt.subplots(figsize=(5, 4))\n","        im = ax.imshow(cm_bin, interpolation=\"nearest\", cmap='Blues')\n","        ax.set_title(f\"One-vs-Rest: {lbl}\", fontsize=12, fontweight='bold')\n","        ax.set_xticks([0, 1])\n","        ax.set_yticks([0, 1])\n","        ax.set_xticklabels([\"Other\", lbl], rotation=0)\n","        ax.set_yticklabels([\"Other\", lbl])\n","\n","        for (i, j), v in np.ndenumerate(cm_bin):\n","            ax.text(j, i, str(v), ha=\"center\", va=\"center\", fontsize=10,\n","                    color=\"white\" if v > cm_bin.max()/2 else \"black\")\n","\n","        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","        pth = os.path.join(out_dir, f\"confusion_{lbl.replace('/', '_')}.png\")\n","        plt.tight_layout()\n","        plt.savefig(pth, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        paths[lbl] = pth\n","\n","    return paths"],"metadata":{"id":"Doa2jiC6aFT9","executionInfo":{"status":"ok","timestamp":1756600090792,"user_tz":-480,"elapsed":3,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def analyse_feature_contributions(\n","    model: HybridModelWrapper,\n","    texts: List[str],\n","    features_df: pd.DataFrame,\n","    feature_names: List[str],\n","    out_dir: str,\n","    random_state: int = 7,\n","    max_features: int = 30,\n","    use_shap: bool = False,\n",") -> Dict:\n","    \"\"\"\n","    Analyze feature contributions for hybrid model.\n","    \"\"\"\n","    _ensure_dir(out_dir)\n","    result = {\"summary_table\": None, \"plots\": {}}\n","\n","    try:\n","        # Get predictions to understand model behavior\n","        y_pred, y_proba = model.predict(texts, features_df)\n","\n","        # Sample a subset for analysis\n","        sample_n = min(100, len(texts))\n","        rng = np.random.RandomState(random_state)\n","        sample_indices = rng.choice(len(texts), sample_n, replace=False)\n","        sample_texts = [texts[i] for i in sample_indices]\n","        sample_proba = y_proba[sample_indices]\n","\n","        # Calculate basic statistics\n","        pred_variance = np.var(sample_proba, axis=0)\n","        pred_mean = np.mean(sample_proba, axis=0)\n","\n","        # Create a simple importance measure\n","        class_names = model.get_label_names()\n","        importance_data = []\n","\n","        for i, class_name in enumerate(class_names):\n","            importance_data.append({\n","                'feature': f'Class_{i}_{class_name}_variance',\n","                'importance': pred_variance[i]\n","            })\n","            importance_data.append({\n","                'feature': f'Class_{i}_{class_name}_mean_prob',\n","                'importance': pred_mean[i]\n","            })\n","\n","        # Convert to DataFrame and save\n","        k = min(max_features, len(importance_data))\n","        fi_df = pd.DataFrame(importance_data).sort_values(\n","            \"importance\", ascending=False\n","        ).head(k).reset_index(drop=True)\n","\n","        table_pth = os.path.join(out_dir, \"hybrid_model_analysis.csv\")\n","        fi_df.to_csv(table_pth, index=False)\n","\n","        # Create a visualization\n","        fig, ax = plt.subplots(figsize=(10, max(6, 0.4 * len(fi_df))))\n","        bars = ax.barh(fi_df[\"feature\"][::-1], fi_df[\"importance\"][::-1],\n","                       color='skyblue', alpha=0.7)\n","        ax.set_title(\"Hybrid Model Analysis (Prediction Statistics)\",\n","                     fontsize=14, fontweight='bold')\n","        ax.set_xlabel(\"Value\", fontsize=12)\n","        ax.grid(axis='x', alpha=0.3)\n","\n","        # Add value labels on bars\n","        for bar in bars:\n","            width = bar.get_width()\n","            ax.text(width + width*0.01, bar.get_y() + bar.get_height()/2,\n","                    f'{width:.3f}', ha='left', va='center', fontsize=8)\n","\n","        plt.tight_layout()\n","        bar_pth = os.path.join(out_dir, \"hybrid_model_analysis.png\")\n","        plt.savefig(bar_pth, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","\n","        result[\"summary_table\"] = fi_df.to_dict(orient=\"records\")\n","        result[\"plots\"][\"bar\"] = bar_pth\n","\n","    except Exception as e:\n","        warnings.warn(f\"Hybrid model analysis failed: {e}\")\n","\n","    return result\n","\n","def examine_misclassified_samples(\n","    y_true: np.ndarray,\n","    y_pred: np.ndarray,\n","    labels: List[str],\n","    y_proba: Optional[np.ndarray] = None,\n","    texts: Optional[List[str]] = None,\n","    top_n: int = 50\n",") -> pd.DataFrame:\n","    \"\"\"Return a table of misclassified rows, with confidence and margin if available.\"\"\"\n","    idx_mis = np.where(y_true != y_pred)[0]\n","    if idx_mis.size == 0:\n","        return pd.DataFrame(columns=[\"index\", \"true\", \"pred\", \"pred_conf\", \"margin\", \"text\"])\n","\n","    pred_conf = _safe_proba_to_confidence(y_proba, y_pred)\n","    pred_conf_sel = pred_conf[idx_mis]\n","\n","    margin = np.full_like(pred_conf_sel, fill_value=np.nan, dtype=float)\n","    if y_proba is not None and y_proba.ndim == 2:\n","        rows = idx_mis\n","        y_proba_rows = y_proba[rows]\n","        preds = y_pred[rows]\n","        best = y_proba_rows[np.arange(len(rows)), preds]\n","        y_proba_masked = y_proba_rows.copy()\n","        y_proba_masked[np.arange(len(rows)), preds] = -np.inf\n","        second = np.max(y_proba_masked, axis=1)\n","        margin = best - second\n","\n","    recs = []\n","    for i, conf, m in zip(idx_mis, pred_conf_sel, margin):\n","        recs.append({\n","            \"index\": int(i),\n","            \"true\": labels[int(y_true[i])],\n","            \"pred\": labels[int(y_pred[i])],\n","            \"pred_conf\": None if np.isnan(conf) else float(conf),\n","            \"margin\": None if np.isnan(m) else float(m),\n","            \"text\": (texts[i] if texts is not None else None)\n","        })\n","    df = pd.DataFrame(recs).sort_values([\"pred_conf\"], ascending=[False], na_position=\"last\").head(top_n)\n","    return df"],"metadata":{"id":"e6c3o_9MaOA3","executionInfo":{"status":"ok","timestamp":1756600090805,"user_tz":-480,"elapsed":8,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["def calculate_false_positive_costs(\n","    y_true: np.ndarray,\n","    y_pred: np.ndarray,\n","    cost_matrix: pd.DataFrame,\n","    labels: List[str]\n",") -> Dict:\n","    \"\"\"\n","    cost_matrix[row=true, col=pred] = unit cost of that error.\n","    Index and columns must exactly match labels.\n","    \"\"\"\n","    if list(cost_matrix.index) != labels or list(cost_matrix.columns) != labels:\n","        raise ValueError(\"Cost matrix index/columns must exactly match labels order.\")\n","\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n","    total_cost = 0.0\n","    breakdown = []\n","    for i_true, true_lbl in enumerate(labels):\n","        for j_pred, pred_lbl in enumerate(labels):\n","            n = int(cm[i_true, j_pred])\n","            unit_cost = float(cost_matrix.loc[true_lbl, pred_lbl])\n","            c = n * unit_cost\n","            if n > 0:\n","                breakdown.append({\n","                    \"true\": true_lbl,\n","                    \"pred\": pred_lbl,\n","                    \"count\": n,\n","                    \"unit_cost\": unit_cost,\n","                    \"cost\": c\n","                })\n","            total_cost += c\n","\n","    return {\"total_cost\": total_cost, \"breakdown\": breakdown}"],"metadata":{"id":"h53HYf3SaUf1","executionInfo":{"status":"ok","timestamp":1756600090811,"user_tz":-480,"elapsed":1,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["def evaluate_hybrid_model(\n","    model_path: str,\n","    y_true: np.ndarray,\n","    texts: List[str],\n","    features_df: pd.DataFrame,\n","    labels: List[str] = None,\n","    cost_matrix: Optional[pd.DataFrame] = None,\n","    out_dir: str = \"/content/reports\"\n",") -> Dict:\n","    \"\"\"\n","    Run full evaluation suite for hybrid model and save artifacts in out_dir.\n","    Returns a dictionary for quick logging.\n","    \"\"\"\n","    _ensure_dir(out_dir)\n","\n","    # Load the hybrid model\n","    print(\"ü§ñ Loading hybrid model...\")\n","    model = HybridModelWrapper(model_path, device=CONFIG['device'])\n","\n","    # Get label names from model if not provided\n","    if labels is None:\n","        labels = model.get_label_names()\n","\n","    print(f\"üè∑Ô∏è  Using labels: {labels}\")\n","\n","    # Get predictions\n","    print(\"üîÆ Making predictions...\")\n","    y_pred, y_proba = model.predict(texts, features_df, batch_size=CONFIG['batch_size'])\n","\n","    # 1) Per-class metrics\n","    print(\"üìä Computing metrics...\")\n","    report = per_class_metrics(y_true, y_pred, labels)\n","    with open(os.path.join(out_dir, \"classification_report.json\"), \"w\") as f:\n","        json.dump(report, f, indent=2)\n","\n","    # 2) Confusion matrices\n","    print(\"üìà Creating confusion matrices...\")\n","    cm_dir = os.path.join(out_dir, \"confusion_matrices\")\n","    cm_paths = plot_confusion_matrix_per_policy(y_true, y_pred, labels, out_dir=cm_dir)\n","\n","    # 3) Feature importance (simplified for hybrid model)\n","    print(\"üîç Analyzing feature contributions...\")\n","    fi_result = None\n","    try:\n","        fi_dir = os.path.join(out_dir, \"feature_importance\")\n","        fi_result = analyse_feature_contributions(\n","            model, texts, features_df, labels, out_dir=fi_dir\n","        )\n","    except Exception as e:\n","        warnings.warn(f\"Feature importance analysis failed: {e}\")\n","\n","    # 4) Error analysis\n","    print(\"üî¨ Examining misclassified samples...\")\n","    err_df = examine_misclassified_samples(\n","        y_true=y_true, y_pred=y_pred, labels=labels, y_proba=y_proba, texts=texts, top_n=100\n","    )\n","    err_path = os.path.join(out_dir, \"misclassified_top.csv\")\n","    err_df.to_csv(err_path, index=False)\n","\n","    # 5) Business impact (optional)\n","    business = None\n","    if cost_matrix is not None:\n","        print(\"üí∞ Calculating business impact...\")\n","        business = calculate_false_positive_costs(y_true, y_pred, cost_matrix, labels=labels)\n","        with open(os.path.join(out_dir, \"business_impact.json\"), \"w\") as f:\n","            json.dump(business, f, indent=2)\n","\n","    # Print summary\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"üìã EVALUATION SUMMARY\")\n","    print(\"=\"*60)\n","    print(f\"‚úÖ Accuracy: {report['accuracy']:.4f}\")\n","    print(f\"üìä Macro F1: {report['macro avg']['f1-score']:.4f}\")\n","    print(f\"‚öñÔ∏è  Weighted F1: {report['weighted avg']['f1-score']:.4f}\")\n","\n","    print(\"\\nüìà Per-Class Performance:\")\n","    for label in labels:\n","        if label in report:\n","            print(f\"   {label}:\")\n","            print(f\"     Precision: {report[label]['precision']:.4f}\")\n","            print(f\"     Recall:    {report[label]['recall']:.4f}\")\n","            print(f\"     F1-Score:  {report[label]['f1-score']:.4f}\")\n","\n","    return {\n","        \"model\": model,\n","        \"y_pred\": y_pred,\n","        \"y_proba\": y_proba,\n","        \"per_class_metrics\": report,\n","        \"confusion_matrices\": cm_paths,\n","        \"feature_importance\": fi_result,\n","        \"error_analysis_csv\": err_path,\n","        \"business_impact_analysis\": business,\n","        \"out_dir\": out_dir\n","    }"],"metadata":{"id":"86IwLd12aYRV","executionInfo":{"status":"ok","timestamp":1756600090824,"user_tz":-480,"elapsed":1,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["print(\"üì¶ Loading packaged test data...\")\n","\n","# Define paths (adjust these to match your actual paths)\n","BASE_DIR = os.path.join(CONFIG['base_path'], 'preprocessed_data')\n","PROCESSED_TEST_FILE = os.path.join(BASE_DIR, \"processed_test.pkl\")\n","METADATA_FILE = os.path.join(BASE_DIR, \"feature_metadata.json\")\n","ENCODERS_FILE = os.path.join(BASE_DIR, \"encoders.pkl\")\n","\n","try:\n","    #Load test dataset\n","    with open(PROCESSED_TEST_FILE, \"rb\") as f:\n","        test_data = pickle.load(f)\n","\n","    # Load metadata\n","    with open(METADATA_FILE, \"r\") as f:\n","        metadata = json.load(f)\n","\n","    # Load encoders\n","    with open(ENCODERS_FILE, \"rb\") as f:\n","        encoders_dict = pickle.load(f)\n","\n","  # Load metadata\n","    with open(METADATA_FILE, \"r\") as f:\n","        metadata = json.load(f)\n","\n","    # Load encoders\n","    with open(ENCODERS_FILE, \"rb\") as f:\n","        encoders_dict = pickle.load(f)\n","\n","    print(f\"‚úÖ Loaded test data: {len(test_data['labels'])} samples\")\n","\n","    # Extract test components\n","    test_texts = test_data['review_text']\n","    test_labels = np.array(test_data['labels'])  # Already encoded labels\n","\n","    # Create features DataFrame for the hybrid model\n","    # The hybrid model expects a DataFrame with both categorical and continuous features\n","    test_features_df = pd.DataFrame()\n","\n","    # Add review text for matching (needed by HybridModelWrapper.prepare_features)\n","    test_features_df['review_text'] = test_texts\n","\n","    # Add categorical features\n","    categorical_features = np.array(test_data['categorical_features'])\n","    for i, col_name in enumerate(metadata['categorical_features']['feature_names']):\n","        test_features_df[col_name] = categorical_features[:, i]\n","\n","    # Add continuous features\n","    continuous_features = np.array(test_data['continuous_features'])\n","    for i, col_name in enumerate(metadata['continuous_features']['feature_names']):\n","        test_features_df[col_name] = continuous_features[:, i]\n","\n","    # Get class names from metadata\n","    class_names = metadata['labels']['class_names']\n","\n","    print(f\"üìä Test dataset shape: {len(test_texts)} samples\")\n","    print(f\"üè∑Ô∏è  Classes: {class_names}\")\n","    print(f\"üìà Label distribution:\")\n","    unique, counts = np.unique(test_labels, return_counts=True)\n","    for label_idx, count in zip(unique, counts):\n","        print(f\"   {class_names[label_idx]}: {count} samples ({count/len(test_labels)*100:.1f}%)\")\n","\n","    print(\"‚úÖ Test data loaded successfully!\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error loading test data: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klz-wEq_ai7u","executionInfo":{"status":"ok","timestamp":1756600127561,"user_tz":-480,"elapsed":5468,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"2bcf61aa-d415-4118-912d-1862e66fd9f4"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Loading packaged test data...\n","‚úÖ Loaded test data: 502 samples\n","üìä Test dataset shape: 502 samples\n","üè∑Ô∏è  Classes: ['Spam/Advertisement', 'Irrelevant Content', 'Rant/Complaint (without visit)', 'Relevant and Quality']\n","üìà Label distribution:\n","   Spam/Advertisement: 1 samples (0.2%)\n","   Irrelevant Content: 123 samples (24.5%)\n","   Rant/Complaint (without visit): 2 samples (0.4%)\n","   Relevant and Quality: 376 samples (74.9%)\n","‚úÖ Test data loaded successfully!\n"]}]},{"cell_type":"code","source":["print(\"ü§ñ Loading trained hybrid model...\")\n","TRAINED_MODEL_PATH = os.path.join(CONFIG['base_path'], 'final_model_enhanced')\n","\n","try:\n","    # Load the HybridModelWrapper - corrected initialization\n","    classifier = HybridModelWrapper(TRAINED_MODEL_PATH, device=CONFIG['device'])\n","    print(\"‚úÖ Successfully loaded hybrid model with custom wrapper\")\n","except Exception as e:\n","    print(f\"‚ùå Error loading hybrid model: {e}\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJaIwCCJfnf3","executionInfo":{"status":"ok","timestamp":1756600137912,"user_tz":-480,"elapsed":1178,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"eaa8dc9b-a7f8-46ae-d538-230154dfeea8"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["ü§ñ Loading trained hybrid model...\n","‚úÖ Hybrid model loaded successfully on device: cuda\n","‚úÖ Successfully loaded hybrid model with custom wrapper\n"]}]},{"cell_type":"code","source":["# Optional: Create a cost matrix for business impact analysis\n","print(\"üí∞ Setting up cost matrix for business impact analysis...\")\n","\n","# Define costs for misclassification (adjust these values based on your business needs)\n","# Higher values = more costly errors\n","cost_data = [\n","    #     spam_ad  irrelevant  rant_without_visit  relevant_and_quality\n","    [0.0,      2.0,        1.5,               5.0],  # true: spam_ad\n","    [1.0,      0.0,        1.0,               3.0],  # true: irrelevant\n","    [2.0,      1.5,        0.0,               4.0],  # true: rant_without_visit\n","    [8.0,      5.0,        6.0,               0.0]   # true: relevant_and_quality\n","]\n","\n","cost_matrix = pd.DataFrame(\n","    cost_data,\n","    index=class_names,\n","    columns=class_names\n",")\n","\n","print(\"üí∏ Cost Matrix (rows=true, cols=predicted):\")\n","print(cost_matrix)\n","print(\"\\nNote: Higher values indicate more costly misclassification errors\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIdZaP1LftB7","executionInfo":{"status":"ok","timestamp":1756600149384,"user_tz":-480,"elapsed":41,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"5fa0dc67-5c64-4f24-b52f-324e1de5e372"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["üí∞ Setting up cost matrix for business impact analysis...\n","üí∏ Cost Matrix (rows=true, cols=predicted):\n","                                Spam/Advertisement  Irrelevant Content  \\\n","Spam/Advertisement                             0.0                 2.0   \n","Irrelevant Content                             1.0                 0.0   \n","Rant/Complaint (without visit)                 2.0                 1.5   \n","Relevant and Quality                           8.0                 5.0   \n","\n","                                Rant/Complaint (without visit)  \\\n","Spam/Advertisement                                         1.5   \n","Irrelevant Content                                         1.0   \n","Rant/Complaint (without visit)                             0.0   \n","Relevant and Quality                                       6.0   \n","\n","                                Relevant and Quality  \n","Spam/Advertisement                               5.0  \n","Irrelevant Content                               3.0  \n","Rant/Complaint (without visit)                   4.0  \n","Relevant and Quality                             0.0  \n","\n","Note: Higher values indicate more costly misclassification errors\n"]}]},{"cell_type":"code","source":["# Run the comprehensive evaluation\n","print(\"\\nüöÄ Starting comprehensive model evaluation...\")\n","print(\"=\"*60)\n","\n","try:\n","    # Create output directory with timestamp\n","    from datetime import datetime\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_dir = os.path.join(CONFIG['base_path'], f\"evaluation_reports_{timestamp}\")\n","\n","    result = evaluate_hybrid_model(\n","        model_path=TRAINED_MODEL_PATH,\n","        y_true=test_labels,\n","        texts=test_texts,\n","        features_df=test_features_df,\n","        labels=class_names,\n","        cost_matrix=cost_matrix,  # Comment this out if you don't want business impact analysis\n","        out_dir=output_dir\n","    )\n","\n","    print(\"\\nüéâ Evaluation completed successfully!\")\n","    print(f\"üìÅ All reports saved to: {result['out_dir']}\")\n","\n","    # Additional detailed analysis\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"üìä DETAILED RESULTS ANALYSIS\")\n","    print(\"=\"*60)\n","\n","    # Show confusion matrix in text format\n","    from sklearn.metrics import confusion_matrix\n","    cm = confusion_matrix(test_labels, result['y_pred'])\n","\n","    print(f\"\\nüìà Confusion Matrix:\")\n","    print(f\"{'':>15} \" + \" \".join(f\"{name[:8]:>8}\" for name in class_names))\n","    for i, true_label in enumerate(class_names):\n","        row = f\"{true_label[:15]:>15} \"\n","        row += \" \".join(f\"{cm[i,j]:>8}\" for j in range(len(class_names)))\n","        print(row)\n","\n","    # Show top misclassified examples\n","    if os.path.exists(result['error_analysis_csv']):\n","        error_df = pd.read_csv(result['error_analysis_csv'])\n","        if not error_df.empty:\n","            print(f\"\\nüîç Top 5 Misclassified Examples:\")\n","            for idx, row in error_df.head(5).iterrows():\n","                print(f\"\\n  Example {idx+1}:\")\n","                print(f\"    True: {row['true']} | Predicted: {row['pred']}\")\n","                print(f\"    Confidence: {row['pred_conf']:.3f}\")\n","                if pd.notna(row['text']) and len(str(row['text'])) > 0:\n","                    text_preview = str(row['text'])[:100] + \"...\" if len(str(row['text'])) > 100 else str(row['text'])\n","                    print(f\"    Text: {text_preview}\")\n","\n","    # Business impact summary\n","    if result['business_impact_analysis']:\n","        total_cost = result['business_impact_analysis']['total_cost']\n","        print(f\"\\nüí∞ Business Impact Analysis:\")\n","        print(f\"    Total misclassification cost: {total_cost:.2f}\")\n","\n","        # Show top 3 most costly error types\n","        breakdown = result['business_impact_analysis']['breakdown']\n","        if breakdown:\n","            sorted_breakdown = sorted(breakdown, key=lambda x: x['cost'], reverse=True)\n","            print(f\"    Top 3 most costly error types:\")\n","            for i, error in enumerate(sorted_breakdown[:3], 1):\n","                print(f\"      {i}. {error['true']} ‚Üí {error['pred']}: \"\n","                      f\"{error['count']} cases, cost = {error['cost']:.2f}\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Error during evaluation: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOTDk_ePkMbp","executionInfo":{"status":"ok","timestamp":1756600156870,"user_tz":-480,"elapsed":7485,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"c9819872-c41e-421c-8059-62c67c374d2b"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üöÄ Starting comprehensive model evaluation...\n","============================================================\n","ü§ñ Loading hybrid model...\n","‚úÖ Hybrid model loaded successfully on device: cuda\n","üè∑Ô∏è  Using labels: ['Spam/Advertisement', 'Irrelevant Content', 'Rant/Complaint (without visit)', 'Relevant and Quality']\n","üîÆ Making predictions...\n"]},{"output_type":"stream","name":"stderr","text":["Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:02<00:00,  7.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["üìä Computing metrics...\n","üìà Creating confusion matrices...\n","üîç Analyzing feature contributions...\n"]},{"output_type":"stream","name":"stderr","text":["Making predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:01<00:00, 14.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["üî¨ Examining misclassified samples...\n","üí∞ Calculating business impact...\n","\n","============================================================\n","üìã EVALUATION SUMMARY\n","============================================================\n","‚úÖ Accuracy: 0.5558\n","üìä Macro F1: 0.3410\n","‚öñÔ∏è  Weighted F1: 0.6720\n","\n","üìà Per-Class Performance:\n","   Spam/Advertisement:\n","     Precision: 0.0000\n","     Recall:    0.0000\n","     F1-Score:  0.0000\n","   Irrelevant Content:\n","     Precision: 0.7711\n","     Recall:    0.5203\n","     F1-Score:  0.6214\n","   Rant/Complaint (without visit):\n","     Precision: 0.0256\n","     Recall:    0.5000\n","     F1-Score:  0.0488\n","   Relevant and Quality:\n","     Precision: 0.8880\n","     Recall:    0.5691\n","     F1-Score:  0.6937\n","\n","üéâ Evaluation completed successfully!\n","üìÅ All reports saved to: /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909\n","\n","============================================================\n","üìä DETAILED RESULTS ANALYSIS\n","============================================================\n","\n","üìà Confusion Matrix:\n","                Spam/Adv Irreleva Rant/Com Relevant\n","Spam/Advertisem        0        0        0        1\n","Irrelevant Cont       29       64        4       26\n","Rant/Complaint         1        0        1        0\n","Relevant and Qu      109       19       34      214\n","\n","üîç Top 5 Misclassified Examples:\n","\n","  Example 1:\n","    True: Irrelevant Content | Predicted: Rant/Complaint (without visit)\n","    Confidence: 1.000\n","    Text: dirty\n","\n","  Example 2:\n","    True: Relevant and Quality | Predicted: Rant/Complaint (without visit)\n","    Confidence: 0.866\n","    Text: enjoyed meeting, the new owner tim, in the new location next barre city hall,\n","to shop for our weddin...\n","\n","  Example 3:\n","    True: Irrelevant Content | Predicted: Rant/Complaint (without visit)\n","    Confidence: 0.693\n","    Text: not bad\n","\n","  Example 4:\n","    True: Relevant and Quality | Predicted: Rant/Complaint (without visit)\n","    Confidence: 0.661\n","    Text: very clean theater, terrible popcorn. don't buy refill popcorn. they sell you old popcorn thats alre...\n","\n","  Example 5:\n","    True: Relevant and Quality | Predicted: Rant/Complaint (without visit)\n","    Confidence: 0.613\n","    Text: a little too dirty, crowded and the slide is not operational. kid had a blast.\n","\n","üí∞ Business Impact Analysis:\n","    Total misclassification cost: 1289.00\n","    Top 3 most costly error types:\n","      1. Relevant and Quality ‚Üí Spam/Advertisement: 109 cases, cost = 872.00\n","      2. Relevant and Quality ‚Üí Rant/Complaint (without visit): 34 cases, cost = 204.00\n","      3. Relevant and Quality ‚Üí Irrelevant Content: 19 cases, cost = 95.00\n"]}]},{"cell_type":"code","source":["# Create additional visualizations\n","print(\"\\nüìä Creating additional visualizations...\")\n","\n","try:\n","    # 1. Class distribution comparison (True vs Predicted)\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","    # True distribution\n","    true_counts = np.bincount(test_labels)\n","    ax1.bar(range(len(class_names)), true_counts, color='lightblue', alpha=0.7)\n","    ax1.set_title('True Label Distribution', fontsize=14, fontweight='bold')\n","    ax1.set_xlabel('Classes')\n","    ax1.set_ylabel('Count')\n","    ax1.set_xticks(range(len(class_names)))\n","    ax1.set_xticklabels(class_names, rotation=45, ha='right')\n","\n","    # Add count labels on bars\n","    for i, count in enumerate(true_counts):\n","        ax1.text(i, count + count*0.01, str(count), ha='center', va='bottom')\n","\n","    # Predicted distribution\n","    pred_counts = np.bincount(result['y_pred'])\n","    ax2.bar(range(len(class_names)), pred_counts, color='lightcoral', alpha=0.7)\n","    ax2.set_title('Predicted Label Distribution', fontsize=14, fontweight='bold')\n","    ax2.set_xlabel('Classes')\n","    ax2.set_ylabel('Count')\n","    ax2.set_xticks(range(len(class_names)))\n","    ax2.set_xticklabels(class_names, rotation=45, ha='right')\n","\n","    # Add count labels on bars\n","    for i, count in enumerate(pred_counts):\n","        ax2.text(i, count + count*0.01, str(count), ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    dist_plot_path = os.path.join(result['out_dir'], 'label_distributions.png')\n","    plt.savefig(dist_plot_path, dpi=300, bbox_inches='tight')\n","    plt.show()\n","    plt.close()\n","\n","    # 2. Prediction confidence distribution\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","\n","    # Get confidence scores for each class\n","    confidence_scores = np.max(result['y_proba'], axis=1)\n","\n","    ax.hist(confidence_scores, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n","    ax.set_title('Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n","    ax.set_xlabel('Confidence Score')\n","    ax.set_ylabel('Frequency')\n","    ax.axvline(np.mean(confidence_scores), color='red', linestyle='--',\n","               label=f'Mean: {np.mean(confidence_scores):.3f}')\n","    ax.axvline(np.median(confidence_scores), color='green', linestyle='--',\n","               label=f'Median: {np.median(confidence_scores):.3f}')\n","    ax.legend()\n","    ax.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    conf_plot_path = os.path.join(result['out_dir'], 'confidence_distribution.png')\n","    plt.savefig(conf_plot_path, dpi=300, bbox_inches='tight')\n","    plt.show()\n","    plt.close()\n","\n","    # 3. Per-class performance radar chart\n","    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n","\n","    metrics = ['precision', 'recall', 'f1-score']\n","    angles = np.linspace(0, 2*np.pi, len(class_names), endpoint=False)\n","\n","    colors = ['red', 'blue', 'green']\n","    for i, metric in enumerate(metrics):\n","        values = [result['per_class_metrics'][class_name][metric] for class_name in class_names]\n","        values += values[:1]  # Complete the circle\n","        angles_plot = np.concatenate([angles, [angles[0]]])\n","\n","        ax.plot(angles_plot, values, 'o-', linewidth=2, label=metric.capitalize(), color=colors[i])\n","        ax.fill(angles_plot, values, alpha=0.1, color=colors[i])\n","\n","    ax.set_xticks(angles)\n","    ax.set_xticklabels(class_names)\n","    ax.set_ylim(0, 1)\n","    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n","    ax.set_title('Per-Class Performance Metrics', fontsize=14, fontweight='bold', pad=20)\n","    ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n","    ax.grid(True)\n","\n","    plt.tight_layout()\n","    radar_plot_path = os.path.join(result['out_dir'], 'performance_radar.png')\n","    plt.savefig(radar_plot_path, dpi=300, bbox_inches='tight')\n","    plt.show()\n","    plt.close()\n","\n","    print(f\"‚úÖ Additional visualizations saved:\")\n","    print(f\"   üìä Label distributions: {os.path.basename(dist_plot_path)}\")\n","    print(f\"   üìà Confidence distribution: {os.path.basename(conf_plot_path)}\")\n","    print(f\"   üéØ Performance radar: {os.path.basename(radar_plot_path)}\")\n","\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Warning: Could not create additional visualizations: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVlkvv_lfx52","executionInfo":{"status":"ok","timestamp":1756600158174,"user_tz":-480,"elapsed":1294,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"8e406548-2797-46f4-f61b-6873c10fae5b"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Creating additional visualizations...\n","‚úÖ Additional visualizations saved:\n","   üìä Label distributions: label_distributions.png\n","   üìà Confidence distribution: confidence_distribution.png\n","   üéØ Performance radar: performance_radar.png\n"]}]},{"cell_type":"code","source":["# Generate a comprehensive summary report\n","print(\"\\nüìù Generating comprehensive summary report...\")\n","\n","try:\n","    summary_path = os.path.join(result['out_dir'], 'evaluation_summary.txt')\n","\n","    with open(summary_path, 'w') as f:\n","        f.write(\"=\"*80 + \"\\n\")\n","        f.write(\"TIKTOK CONTENT CLASSIFICATION - MODEL EVALUATION REPORT\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        f.write(f\"Evaluation Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(f\"Model Path: {TRAINED_MODEL_PATH}\\n\")\n","        f.write(f\"Test Samples: {len(test_labels)}\\n\")\n","        f.write(f\"Classes: {', '.join(class_names)}\\n\\n\")\n","\n","        f.write(\"OVERALL PERFORMANCE METRICS\\n\")\n","        f.write(\"-\" * 40 + \"\\n\")\n","        f.write(f\"Accuracy:     {result['per_class_metrics']['accuracy']:.4f}\\n\")\n","        f.write(f\"Macro F1:     {result['per_class_metrics']['macro avg']['f1-score']:.4f}\\n\")\n","        f.write(f\"Weighted F1:  {result['per_class_metrics']['weighted avg']['f1-score']:.4f}\\n\")\n","        f.write(f\"Macro Precision: {result['per_class_metrics']['macro avg']['precision']:.4f}\\n\")\n","        f.write(f\"Macro Recall:    {result['per_class_metrics']['macro avg']['recall']:.4f}\\n\\n\")\n","\n","        f.write(\"PER-CLASS DETAILED METRICS\\n\")\n","        f.write(\"-\" * 40 + \"\\n\")\n","        f.write(f\"{'Class':<20} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\\n\")\n","        f.write(\"-\" * 60 + \"\\n\")\n","\n","        for class_name in class_names:\n","            if class_name in result['per_class_metrics']:\n","                metrics = result['per_class_metrics'][class_name]\n","                f.write(f\"{class_name:<20} {metrics['precision']:<10.4f} \"\n","                       f\"{metrics['recall']:<10.4f} {metrics['f1-score']:<10.4f} \"\n","                       f\"{int(metrics['support']):<10}\\n\")\n","\n","        f.write(\"\\nCONFUSION MATRIX\\n\")\n","        f.write(\"-\" * 40 + \"\\n\")\n","        cm = confusion_matrix(test_labels, result['y_pred'])\n","        f.write(f\"{'':>15} \" + \" \".join(f\"{name[:8]:>8}\" for name in class_names) + \"\\n\")\n","        for i, true_label in enumerate(class_names):\n","            row = f\"{true_label[:15]:>15} \"\n","            row += \" \".join(f\"{cm[i,j]:>8}\" for j in range(len(class_names)))\n","            f.write(row + \"\\n\")\n","\n","        f.write(\"\\nMODEL CONFIDENCE ANALYSIS\\n\")\n","        f.write(\"-\" * 40 + \"\\n\")\n","        confidence_scores = np.max(result['y_proba'], axis=1)\n","        f.write(f\"Mean Confidence: {np.mean(confidence_scores):.4f}\\n\")\n","        f.write(f\"Median Confidence: {np.median(confidence_scores):.4f}\\n\")\n","        f.write(f\"Std Confidence: {np.std(confidence_scores):.4f}\\n\")\n","        f.write(f\"Min Confidence: {np.min(confidence_scores):.4f}\\n\")\n","        f.write(f\"Max Confidence: {np.max(confidence_scores):.4f}\\n\")\n","\n","        # Low confidence predictions\n","        low_conf_threshold = 0.7\n","        low_conf_mask = confidence_scores < low_conf_threshold\n","        f.write(f\"\\nLow Confidence Predictions (< {low_conf_threshold}):\\n\")\n","        f.write(f\"Count: {np.sum(low_conf_mask)} ({np.sum(low_conf_mask)/len(confidence_scores)*100:.1f}%)\\n\")\n","\n","        if result['business_impact_analysis']:\n","            f.write(\"\\nBUSINESS IMPACT ANALYSIS\\n\")\n","            f.write(\"-\" * 40 + \"\\n\")\n","            f.write(f\"Total Misclassification Cost: {result['business_impact_analysis']['total_cost']:.2f}\\n\")\n","            f.write(f\"Average Cost per Sample: {result['business_impact_analysis']['total_cost']/len(test_labels):.4f}\\n\\n\")\n","\n","            f.write(\"Cost Breakdown by Error Type:\\n\")\n","            breakdown = result['business_impact_analysis']['breakdown']\n","            sorted_breakdown = sorted(breakdown, key=lambda x: x['cost'], reverse=True)\n","            for error in sorted_breakdown[:10]:  # Top 10 most costly\n","                f.write(f\"  {error['true']} ‚Üí {error['pred']}: {error['count']} cases, \"\n","                       f\"cost = {error['cost']:.2f}\\n\")\n","\n","        f.write(f\"\\n\\nREPORT GENERATED: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(\"=\"*80 + \"\\n\")\n","\n","    print(f\"üìÑ Summary report saved: {os.path.basename(summary_path)}\")\n","\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Warning: Could not generate summary report: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmMjUw_ifz-R","executionInfo":{"status":"ok","timestamp":1756600158188,"user_tz":-480,"elapsed":4,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"03cd0ebb-f761-4423-b43d-7ebf4e4bde20"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìù Generating comprehensive summary report...\n","üìÑ Summary report saved: evaluation_summary.txt\n"]}]},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*80)\n","print(\"üéâ MODEL EVALUATION COMPLETED SUCCESSFULLY!\")\n","print(\"=\"*80)\n","\n","print(f\"\\nüìä FINAL RESULTS SUMMARY:\")\n","print(f\"   üéØ Accuracy: {result['per_class_metrics']['accuracy']:.4f}\")\n","print(f\"   üìà Macro F1: {result['per_class_metrics']['macro avg']['f1-score']:.4f}\")\n","print(f\"   ‚öñÔ∏è  Weighted F1: {result['per_class_metrics']['weighted avg']['f1-score']:.4f}\")\n","\n","if result['business_impact_analysis']:\n","    print(f\"   üí∞ Total Cost: {result['business_impact_analysis']['total_cost']:.2f}\")\n","\n","print(f\"\\nüìÅ All evaluation artifacts saved to:\")\n","print(f\"   {result['out_dir']}\")\n","\n","print(f\"\\nüìã Generated Files:\")\n","files_created = [\n","    \"classification_report.json\",\n","    \"confusion_matrices/\",\n","    \"feature_importance/\",\n","    \"misclassified_top.csv\",\n","    \"evaluation_summary.txt\"\n","]\n","\n","if result['business_impact_analysis']:\n","    files_created.append(\"business_impact.json\")\n","\n","for file in files_created:\n","    print(f\"   ‚úÖ {file}\")\n","\n","print(f\"\\nüîó Key file paths:\")\n","print(f\"   üìä Classification Report: {os.path.join(result['out_dir'], 'classification_report.json')}\")\n","print(f\"   üìà Confusion Matrices: {os.path.join(result['out_dir'], 'confusion_matrices')}\")\n","print(f\"   üîç Error Analysis: {result['error_analysis_csv']}\")\n","print(f\"   üìÑ Summary Report: {os.path.join(result['out_dir'], 'evaluation_summary.txt')}\")\n","\n","print(f\"\\nüí° Next Steps:\")\n","print(f\"   1. Review the confusion matrices to understand error patterns\")\n","print(f\"   2. Analyze misclassified samples for model improvement insights\")\n","print(f\"   3. Consider the business impact analysis for deployment decisions\")\n","print(f\"   4. Use the feature importance analysis to understand model behavior\")\n","\n","print(f\"\\nüöÄ Evaluation notebook completed successfully!\")\n","print(\"=\"*80)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WAlsr5Pof2T0","executionInfo":{"status":"ok","timestamp":1756600158200,"user_tz":-480,"elapsed":4,"user":{"displayName":"joshua teo","userId":"08987881000560814542"}},"outputId":"e3be5973-56b3-41d2-aeed-d0274ed6594e"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üéâ MODEL EVALUATION COMPLETED SUCCESSFULLY!\n","================================================================================\n","\n","üìä FINAL RESULTS SUMMARY:\n","   üéØ Accuracy: 0.5558\n","   üìà Macro F1: 0.3410\n","   ‚öñÔ∏è  Weighted F1: 0.6720\n","   üí∞ Total Cost: 1289.00\n","\n","üìÅ All evaluation artifacts saved to:\n","   /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909\n","\n","üìã Generated Files:\n","   ‚úÖ classification_report.json\n","   ‚úÖ confusion_matrices/\n","   ‚úÖ feature_importance/\n","   ‚úÖ misclassified_top.csv\n","   ‚úÖ evaluation_summary.txt\n","   ‚úÖ business_impact.json\n","\n","üîó Key file paths:\n","   üìä Classification Report: /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909/classification_report.json\n","   üìà Confusion Matrices: /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909/confusion_matrices\n","   üîç Error Analysis: /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909/misclassified_top.csv\n","   üìÑ Summary Report: /content/drive/MyDrive/Tiktok_Hackaton/evaluation_reports_20250831_002909/evaluation_summary.txt\n","\n","üí° Next Steps:\n","   1. Review the confusion matrices to understand error patterns\n","   2. Analyze misclassified samples for model improvement insights\n","   3. Consider the business impact analysis for deployment decisions\n","   4. Use the feature importance analysis to understand model behavior\n","\n","üöÄ Evaluation notebook completed successfully!\n","================================================================================\n"]}]}]}